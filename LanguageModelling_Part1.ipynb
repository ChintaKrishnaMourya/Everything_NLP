{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "we will be using the following libraries:\n",
        "\n",
        "pandas for managing the data.\n",
        "numpy for mathematical operations.\n",
        "sklearn for machine learning and machine-learning-pipeline related functions.\n",
        "seaborn for visualizing the data.\n",
        "matplotlib for additional plotting tools."
      ],
      "metadata": {
        "id": "W5oeS3ts4N3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CMBDeiqR4GDf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install nltk\n",
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVkQOjXi4SJo",
        "outputId": "f6385ac3-e3f9-4615-8a71-03cee598876f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all non-word characters (everything except numbers and letters)\n",
        "\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s"
      ],
      "metadata": {
        "id": "FXOMCh5l4w0X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the song by Enya-WildChild\n",
        "song = '''\n",
        "Ever close your eyes\n",
        "Ever stop and listen\n",
        "Ever feel alive\n",
        "And you've nothing missing\n",
        "You don't need a reason\n",
        "Let the day go on and on\n",
        "Let the rain fall down\n",
        "Everywhere around you\n",
        "Give into it now\n",
        "Let the day surround you\n",
        "You don't need a reason\n",
        "Let the rain go on and on\n",
        "What a day\n",
        "What a day to take to\n",
        "What a way\n",
        "What a way to make it through\n",
        "What a day\n",
        "What a day to take to\n",
        "A wild child\n",
        "Only take the time\n",
        "From the Helter Skelter\n",
        "Every day you find\n",
        "Everything's in kilter\n",
        "You don't need a reason\n",
        "Let the day go on and on\n",
        "Every summer sun\n",
        "Every winter evening\n",
        "Every spring to come\n",
        "Every autumn leaving\n",
        "You don't need a reason\n",
        "Let it all go on and on\n",
        "What a day\n",
        "What a day to take to\n",
        "What a way\n",
        "What a way to make it through\n",
        "What a day\n",
        "What a day to take to\n",
        "A wild child\n",
        "What a day\n",
        "What a day to take to\n",
        "What a way\n",
        "What a way to make it through\n",
        "What a day\n",
        "What a day to take to\n",
        "A wild child\n",
        "What a day\n",
        "What a day to take to\n",
        "What a way\n",
        "What a way to make it through\n",
        "What a day\n",
        "What a day to take to\n",
        "Da da da\n",
        "Da da da da da da\n",
        "What a way\n",
        "What a way to make it through\n",
        "Da da da\n",
        "Da da da da da da\n",
        "Da da da\n",
        "Da da da da da da\n",
        "What a way\n",
        "What a way to make it through\n",
        "What a day\n",
        "What a day to take to\n",
        "A wild child\n",
        "What a day\n",
        "What a day to take to\n",
        "A wild child\n",
        "'''"
      ],
      "metadata": {
        "id": "Edy0YoBZ5Cm5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def preprocess(words):\n",
        "    tokens=word_tokenize(words)\n",
        "    #print(tokens, \"\\n\")\n",
        "    tokens=[preprocess_string(w)   for w in tokens]\n",
        "    #print(tokens, \"\\n\")\n",
        "    return [w.lower()  for w in tokens if len(w)!=0 or not(w in string.punctuation) ]\n",
        "\n",
        "tokens=preprocess(song)"
      ],
      "metadata": {
        "id": "HWmT-pMB41n6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens =preprocess(\"hi i am mourya\")"
      ],
      "metadata": {
        "id": "8zvLCCcyoVAi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jZwLBF25BsS",
        "outputId": "94e48142-715b-465f-a7aa-747b3397d96f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ever',\n",
              " 'close',\n",
              " 'your',\n",
              " 'eyes',\n",
              " 'ever',\n",
              " 'stop',\n",
              " 'and',\n",
              " 'listen',\n",
              " 'ever',\n",
              " 'feel']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a frequency distribution of words\n",
        "fdist = nltk.FreqDist(tokens)\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9ezGlvY5Z2Z",
        "outputId": "27a7bb7e-8001-49e8-9f33-e4a8d9170eba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 41, 'what': 32, 'to': 27, 'da': 27, 'day': 24, 'way': 12, 'take': 11, 'you': 8, 'on': 8, 'it': 8, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(list(fdist.keys())[0:10],list(fdist.values())[0:10])\n",
        "plt.xlabel(\"Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "pQ_mBY0R5dEE",
        "outputId": "ca210875-d073-4e74-fdd4-480e585b1e98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## UniGram Model\n",
        "\n",
        "#Using NLTK we can normalize the frequency values by dividing them by the total count\n",
        "#of each word we get a probability function, we can fine the probability of each word\n",
        "C=sum(fdist.values())\n",
        "print(C)\n",
        "\n",
        "#We can find the probability of the word wish i.w  P(wild)\n",
        "fdist['wild']/C\n",
        "\n",
        "# We can also find each individual word by converting our tokens to a set\n",
        "vocabulary=set(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTyUV94P5dXX",
        "outputId": "7ca469ee-d02f-44da-a61c-ed6b6c596606"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Unigram model predicts the next likely word\n",
        "Let's consider a scenario from the above example where we ask the unigram model to predict the next word following the sequence 'I like'.\n",
        "\n",
        "If the highest probability among all words is \"I\" with a probability 0.25, then according to the model, the most likely next word after 'I like' would be 'I'. However, this prediction doesn't make sense at all. This highlights a significant limitation of the unigram model—it lacks context, and its predictions are entirely dependent on the word with the highest probability \"I\" in this case\n",
        "\n",
        "Even if multiple words have the same highest probabilities, it will randomly choose any one word out of all the options."
      ],
      "metadata": {
        "id": "NKFo6RKo6Oof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## BiGram Model\n",
        "\n",
        "#bigrams is a function provided by the Natural Language Toolkit (NLTK) library in Python.\n",
        "# This function takes a sequence of tokens as input and returns an iterator over consecutive pairs of tokens, forming bigrams.\n",
        "bigrams = nltk.bigrams(tokens)\n",
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isTW_IFv5xsC",
        "outputId": "205e0df4-6244-407f-e403-1b8e45d49432"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object bigrams at 0x7c414995ab20>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can convert a generator into a list, where each element of the list is a bigram.\n",
        "my_bigrams=list(nltk.bigrams(tokens))\n",
        "\n",
        "#We can see the first 10 bigrams\n",
        "my_bigrams[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNsvcBwB6fU4",
        "outputId": "812c76d0-6e82-4541-9b6f-09e72dad146f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ever', 'close'),\n",
              " ('close', 'your'),\n",
              " ('your', 'eyes'),\n",
              " ('eyes', 'ever'),\n",
              " ('ever', 'stop'),\n",
              " ('stop', 'and'),\n",
              " ('and', 'listen'),\n",
              " ('listen', 'ever'),\n",
              " ('ever', 'feel'),\n",
              " ('feel', 'alive')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We compute the frequency distribution of the bigram  C(wt,wt−1)  using the NLTK functionbigrams.\n",
        "freq_bigrams  = nltk.FreqDist(nltk.bigrams(tokens))\n",
        "freq_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf8GuSu86odt",
        "outputId": "53972298-d0fe-4bd6-d2b7-2670cfce5eee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('what', 'a'): 32, ('da', 'da'): 25, ('a', 'day'): 20, ('a', 'way'): 12, ('day', 'what'): 10, ('day', 'to'): 10, ('to', 'take'): 10, ('take', 'to'): 10, ('way', 'what'): 6, ('way', 'to'): 6, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can provide you with the first 10 values of the frequency distribution\n",
        "for my_bigram in  my_bigrams[0:10]:\n",
        "    print(my_bigram)\n",
        "    print(freq_bigrams[my_bigram])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rj4zuW06uWn",
        "outputId": "92b6ba2c-3999-4ff5-dbbd-5999bd00c49a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ever', 'close')\n",
            "1\n",
            "('close', 'your')\n",
            "1\n",
            "('your', 'eyes')\n",
            "1\n",
            "('eyes', 'ever')\n",
            "1\n",
            "('ever', 'stop')\n",
            "1\n",
            "('stop', 'and')\n",
            "1\n",
            "('and', 'listen')\n",
            "1\n",
            "('listen', 'ever')\n",
            "1\n",
            "('ever', 'feel')\n",
            "1\n",
            "('feel', 'alive')\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Here, you can generate the conditional distribution by normalizing the frequency distribution of unigrams.\n",
        "#In this case, we are doing it for the word 'wild' and then sorting the results:\n",
        "\n",
        "word=\"wild\"\n",
        "vocab_probabilities={}\n",
        "for next_word in vocabulary:\n",
        "    vocab_probabilities[next_word]=freq_bigrams[(word,next_word)]/fdist[word]\n",
        "\n",
        "vocab_probabilities=sorted(vocab_probabilities.items(), key=lambda x:x[1],reverse=True)\n",
        "vocab_probabilities[0:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFf0YZ9467rU",
        "outputId": "461d67d8-cba2-420d-9794-1144e9a607ef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('child', 1.0), ('surround', 0.0), ('find', 0.0), ('listen', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can create a function to calculate the conditional probability of  Wt  given  Wt−1 , sort the results, and output them as a list.\n",
        "\n",
        "def make_predictions(my_words, freq_grams, normlize=1, vocabulary=vocabulary):\n",
        "    \"\"\"\n",
        "    Generate predictions for the conditional probability of the next word given a sequence.\n",
        "\n",
        "    Args:\n",
        "        my_words (list): A list of words in the input sequence.\n",
        "        freq_grams (dict): A dictionary containing frequency of n-grams.\n",
        "        normlize (int): A normalization factor for calculating probabilities.\n",
        "        vocabulary (list): A list of words in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predicted words along with their probabilities, sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    vocab_probabilities = {}  # Initialize a dictionary to store predicted word probabilities\n",
        "\n",
        "    context_size = len(list(freq_grams.keys())[0])  # Determine the context size from n-grams keys\n",
        "\n",
        "    # Preprocess input words and take only the relevant context words\n",
        "    my_tokens = preprocess(my_words)[0:context_size - 1]\n",
        "\n",
        "    # Calculate probabilities for each word in the vocabulary given the context\n",
        "    for next_word in vocabulary:\n",
        "        temp = my_tokens.copy()\n",
        "        temp.append(next_word)  # Add the next word to the context\n",
        "\n",
        "        # Calculate the conditional probability using the frequency information\n",
        "        if normlize!=0:\n",
        "            vocab_probabilities[next_word] = freq_grams[tuple(temp)] / normlize\n",
        "        else:\n",
        "            vocab_probabilities[next_word] = freq_grams[tuple(temp)]\n",
        "    # Sort the predicted words based on their probabilities in descending order\n",
        "    vocab_probabilities = sorted(vocab_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return vocab_probabilities  # Return the sorted list of predicted words and their probabilities"
      ],
      "metadata": {
        "id": "TlCBKdxE7HPp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(freq_bigrams.keys())[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ty-dWiyqUfl",
        "outputId": "8010351a-cbd7-49a0-8bf7-cae3f15177d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_words=\"wild child of course\"\n",
        "\n",
        "vocab_probabilities=make_predictions(my_words,freq_bigrams,normlize=fdist['i'])\n",
        "vocab_probabilities[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TugCGtAv7zNB",
        "outputId": "06c390be-e7f4-4bf6-ac8e-a2be241fb9a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('child', 5),\n",
              " ('surround', 0),\n",
              " ('find', 0),\n",
              " ('listen', 0),\n",
              " ('ever', 0),\n",
              " ('eyes', 0),\n",
              " ('ve', 0),\n",
              " ('way', 0),\n",
              " ('your', 0),\n",
              " ('everything', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can generate a sequence using our Bigram Model by leveraging the\n",
        "#preceding word (t-1) to predict and generate the subsequent word in the sequence.\n",
        "\n",
        "my_song=\"\"\n",
        "for w in tokens[0:100]:\n",
        "  my_word=make_predictions(w,freq_bigrams)[0][0]\n",
        "  my_song+=\" \"+my_word\n",
        "\n",
        "my_song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "9yuVYwfL70nL",
        "outputId": "ad89e05c-e407-4c7c-a5c9-96077dee54df"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' stop your eyes ever stop and on ever stop alive and on do nothing missing you do nt need a day let the day what on and on and the day go down everywhere around you do into it through let the day what you do do nt need a day let the day go on and on and a day what a day what take to take a day what a day what take it through what a day what a day what take to take day child what take to day from the day skelter every spring what'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can create a sequence using our n-gram model by initiating the process with the first word in the sequence and producing an initial output.\n",
        "#Subsequently, we utilize this output as the basis for generating the next word in the sequence.\n",
        "#i.e we Give our model a word, then use the output to predict the next word and repeat.\n",
        "\n",
        "my_word=\"Mourya\"\n",
        "my_song =\"\"\n",
        "for i in range(100):\n",
        "    my_word=make_predictions(my_word,freq_bigrams)[0][0]\n",
        "    my_song+=\" \"+my_word\n",
        "\n",
        "my_song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Pxg_Oqo08H0e",
        "outputId": "203dc90b-bec8-4c1f-bae8-925b6c194446"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' surround you do nt need a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day what a day'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TriGram Model\n",
        "\n",
        "freq_trigrams  = nltk.FreqDist(nltk.trigrams(tokens))\n",
        "freq_trigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ2ZkikQ9nVr",
        "outputId": "8a91f224-71a4-4bdc-8694-645be7a10026"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('da', 'da', 'da'): 23, ('what', 'a', 'day'): 20, ('what', 'a', 'way'): 12, ('a', 'day', 'what'): 10, ('day', 'what', 'a'): 10, ('a', 'day', 'to'): 10, ('day', 'to', 'take'): 10, ('to', 'take', 'to'): 10, ('a', 'way', 'what'): 6, ('way', 'what', 'a'): 6, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions(\"close your eyes\",freq_trigrams,normlize=freq_bigrams[(\"what\",\"a\")] )[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5C0fN0Y0qmX",
        "outputId": "89360a32-79e2-4e17-f9b7-722ce760c932"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('eyes', 0.03125),\n",
              " ('surround', 0.0),\n",
              " ('find', 0.0),\n",
              " ('listen', 0.0),\n",
              " ('ever', 0.0),\n",
              " ('child', 0.0),\n",
              " ('ve', 0.0),\n",
              " ('way', 0.0),\n",
              " ('your', 0.0),\n",
              " ('everything', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_song=\"\"\n",
        "\n",
        "w1=tokens[0]\n",
        "for w2 in tokens[0:100]:\n",
        "    gram=w1+' '+w2\n",
        "    my_word=make_predictions(gram,freq_trigrams )[0][0]\n",
        "    my_song+=\" \"+my_word\n",
        "    w1=w2\n",
        "\n",
        "my_song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Y3Zxk3XH07g1",
        "outputId": "06c8d36a-5ab2-4eb4-ef18-df61dda51b68"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' surround your eyes ever stop and listen ever feel alive and you ve nothing missing you do nt need a reason let the day go on and on what the day go down everywhere around you give into it now let the day go you you do nt need a reason let the day go on and on what a day what a day what take to a a day what a day what make it through what a day what a day what take to a wild child what take the time from the helter skelter every day you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are various challenges associated with Histogram-Based Methods, some of which are quite straightforward. For instance, when considering the case of having N words in our vocabulary, an Unigram model would entail N bins, while a Bigram model would result in N squared bins and so forth.\n",
        "\n",
        "N-gram models also encounter limitations in terms of contextual understanding and their ability to capture intricate word relationships. For instance, let's consider the phrases `I hate dogs`, `I don’t like dogs`, and **don’t like** means **dislike**. Within this context, a histogram-based approach would fail to grasp the significance of the phrase **don’t like** means **dislike**, thereby missing out on the essential semantic relationship it encapsulates.\n"
      ],
      "metadata": {
        "id": "F0aC0WRy1PJS"
      }
    }
  ]
}